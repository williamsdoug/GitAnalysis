{
 "metadata": {
  "name": "",
  "signature": "sha256:f48920310da43b847265de53f442edf04d1161fd218e360b6717c888d52b91b6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Baseline Blame Analysis for OpenStack Projects using Random Forest\n",
      "\n",
      "Copyright Doug Williams - 2014, 2015\n",
      "\n",
      "###Updated: 3/12/2015\n",
      "\n",
      "###References:\n",
      "- http://research.microsoft.com/pubs/192769/tricks-2012.pdf\n",
      "\n",
      "###Currently best patrams:\n",
      "\n",
      "best_params:  {'n_iter': 100, 'eta0': 0.5, 'shuffle': True, 'loss': 'perceptron', 'learning_rate': 'optimal', 'alpha': 0.0001, 'class_weight': 'auto'}\n",
      "\n",
      "###Result:\n",
      "\n",
      "####Heat:\n",
      "- F1: 0.792546583851\n",
      "- accuracy: 0.833166833167\n",
      "- precision: 0.738425925926\n",
      "- recall: 0.855227882038\n",
      "- confusion matrix\n",
      " - [[515 113]\n",
      " -  [ 54 319]]"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Includes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pprint import pprint\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "import numpy as np\n",
      "import math\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "import sklearn.tree\n",
      "import sklearn.ensemble\n",
      "#from sklearn.svm import SVC\n",
      "#from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from sklearn.cross_validation import ShuffleSplit\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "#from sklearn import metrics\n",
      "\n",
      "# from sklearn.feature_extraction import DictVectorizer\n",
      "# from sklearn.preprocessing import StandardScaler\n",
      "#from sklearn.preprocessing import MinMaxScaler\n",
      "# from sklearn.svm import SVR\n",
      "\n",
      "import sys\n",
      "sys.path.append('./dev')\n",
      "from ml_plot import plot_validation_curve, plot_learning_curve\n",
      "from ml_plot import get_dataset, eval_clf, eval_predictions\n",
      "from ml_plot import PredictCV\n",
      "\n",
      "#from Git_Extract import get_commit_ordering_min_max\n",
      "#from commit_analysis import fit_features\n",
      "#from commit_analysis import extract_features\n",
      "#from commit_analysis import autoset_threshold\n",
      "#from BugFixWorkflow import compute_selected_bug_fixes\n",
      "#from BugFixWorkflow import commit_postprocessing\n",
      "#from BugFixWorkflow import find_legacy_cutoff"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Configuration"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Dataset Selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PROJECT = 'nova'\n",
      "# PROJECT = 'swift'\n",
      "# PROJECT = 'cinder'\n",
      "PROJECT = 'heat'\n",
      "# PROJECT = 'glance'\n",
      "\n",
      "# IMPORTANCE = 'crit'\n",
      "# IMPORTANCE = 'high+'\n",
      "IMPORTANCE = 'med+'\n",
      "# IMPORTANCE = 'low+'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training Parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SIZE = 100\n",
      "#SIZE = 250\n",
      "# SIZE = 0.1\n",
      "SIZE = 0.5\n",
      "\n",
      "SCORING = 'f1'         # (precision * recall) / (precision + recall)\n",
      "# SCORING = 'accuracy'   # (TP + TN) / all values\n",
      "# SCORING = 'precision'  # TP / (TP + FP)\n",
      "# SCORING = 'recall'     # TP / (TP + FN)\n",
      "# SCORING = 'average_precision'\n",
      "# SCORING = 'roc_auc'\n",
      "\n",
      "JOBS = 4\n",
      "\n",
      "VERBOSE = 0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preprocessing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note: Using capture to supress output"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%capture\n",
      "Y, X = get_dataset(PROJECT, IMPORTANCE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Proposed enhancements to training\n",
      "\n",
      "Some speculative thoughts:\n",
      "- Feature Extraction Test/Train\n",
      " - Separately extract features for test/train period, skip latest 20% of commits\n",
      " - Change balance of positive/negative commits to imprpve trainging.  Traioning currently skewed towards negative test vased today\n",
      "- Create validation test suite with latest tests.  Want to measure prediction accuracy for future bugs."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "from sklearn.decomposition import PCA\n",
      "\n",
      "# Note:  Weakness in methodology, really should fix using training set only\n",
      "\n",
      "pca = PCA(n_components='mle')\n",
      "X = pca.fit_transform(X)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Other classifiers to explore\n",
      "- from sklearn.linear_model import LogisticRegression\n",
      " - clf = LogisticRegression()\n",
      "- sklearn.linear_model.SGDClassifier\n",
      "- sklearn.svm.LinearSVC\n",
      "- sklearn.tree.DecisionTreeClassifier"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Train Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = PredictCV(len(Y), history=500, future=100, n_iter=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator = sklearn.ensemble.RandomForestClassifier()\n",
      "param_grid = {'criterion': ['gini', 'entropy'],\n",
      "                  'n_estimators':[5, 7, 10, 11, 13, 15, 17, 19, 23, 25, 29],\n",
      "                  'max_features':['auto', 'log2', 10, 25, 50, 75, 100, 150, 200, 350, 300, 400, 500]  }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "estimator = sklearn.ensemble.RandomForestClassifier()\n",
      "param_grid = {'criterion': ['gini', 'entropy'],\n",
      "                  'n_estimators':[15],\n",
      "                  'max_features':['auto']  }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid = GridSearchCV(estimator, param_grid=param_grid, cv=cv, scoring=SCORING,\n",
      "                    n_jobs=JOBS, pre_dispatch=2*JOBS, verbose=VERBOSE)\n",
      "#grid.fit(X_train, Y_train)\n",
      "grid.fit(X, Y)\n",
      "clf = grid.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'best_params: ',\n",
      "print grid.best_params_\n",
      "print 'best_score: ', grid.best_score_\n",
      "print\n",
      "print \"The best classifier is: \", grid.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best_params:  {'max_features': 'auto', 'n_estimators': 15, 'criterion': 'entropy'}\n",
        "best_score:  0.419784351943\n",
        "\n",
        "The best classifier is:  RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='entropy', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=15, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Now evaluate predictive value"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = eval_predictions(clf, X, Y, history_sizes=[200, 500], future_sizes=[100, 500])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "** Predictions for hist=200 future=100 **\n",
        "\n",
        "F1:        0.27  +/- 0.14\n",
        "Accuracy:  0.73  +/- 0.02\n",
        "Precision: 0.67  +/- 0.18\n",
        "Recall:    0.22  +/- 0.16\n",
        "\n",
        "Aggregate Confusion Matrix - 10 iterations\n",
        "[[17436  1394]\n",
        " [ 5498  1532]]\n",
        "\n",
        "\n",
        "** Predictions for hist=200 future=500 **"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "F1:        0.40  +/- 0.08\n",
        "Accuracy:  0.72  +/- 0.03\n",
        "Precision: 0.50  +/- 0.07\n",
        "Recall:    0.38  +/- 0.14\n",
        "\n",
        "Aggregate Confusion Matrix - 10 iterations\n",
        "[[15932  2898]\n",
        " [ 4386  2644]]\n",
        "\n",
        "\n",
        "** Predictions for hist=500 future=100 **"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "F1:        0.45  +/- 0.10\n",
        "Accuracy:  0.77  +/- 0.02\n",
        "Precision: 0.72  +/- 0.14\n",
        "Recall:    0.38  +/- 0.16\n",
        "\n",
        "Aggregate Confusion Matrix - 10 iterations\n",
        "[[17309  1521]\n",
        " [ 4387  2643]]\n",
        "\n",
        "\n",
        "** Predictions for hist=500 future=500 **"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "F1:        0.52  +/- 0.07\n",
        "Accuracy:  0.77  +/- 0.01\n",
        "Precision: 0.62  +/- 0.10\n",
        "Recall:    0.47  +/- 0.11\n",
        "\n",
        "Aggregate Confusion Matrix - 10 iterations\n",
        "[[16490  2340]\n",
        " [ 3700  3330]]\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 11
    }
   ],
   "metadata": {}
  }
 ]
}