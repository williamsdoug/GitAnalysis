{
 "metadata": {
  "name": "",
  "signature": "sha256:b6149ce724ca74d2a5c10026f2f8972b3a9d12a7cba3d3374765905162428380"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Window-based Blame Analysis for OpenStack Projects\n",
      "\n",
      "Copyright Doug Williams - 2014, 2015\n",
      "\n",
      "###Updated: 2/11/2015"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Includes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pprint import pprint\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "import numpy as np\n",
      "import math\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from sklearn.cross_validation import ShuffleSplit\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import metrics\n",
      "\n",
      "# from sklearn.feature_extraction import DictVectorizer\n",
      "# from sklearn.preprocessing import StandardScaler\n",
      "#from sklearn.preprocessing import MinMaxScaler\n",
      "# from sklearn.svm import SVR\n",
      "\n",
      "import sys\n",
      "sys.path.append('./dev')\n",
      "\n",
      "from Git_Extract import  filter_bug_fix_combined_commits\n",
      "from Git_Extract import get_commit_ordering_min_max\n",
      "\n",
      "from commit_analysis import load_core_analysis_data\n",
      "from commit_analysis import fit_features\n",
      "from commit_analysis import extract_features\n",
      "from commit_analysis import compute_guilt\n",
      "from commit_analysis import autoset_threshold\n",
      "\n",
      "from BugFixWorkflow import commit_postprocessing\n",
      "from BugFixWorkflow import compute_selected_bug_fixes\n",
      "from BugFixWorkflow import find_legacy_cutoff\n",
      "\n",
      "# from commit_analysis import blame_compute_normalized_guilt\n",
      "# from commit_analysis import normalize_blame_by_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Configuration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PROJECT = 'nova'\n",
      "# PROJECT = 'swift'\n",
      "# PROJECT = 'cinder'\n",
      "PROJECT = 'heat'\n",
      "#PROJECT = 'glance'\n",
      "\n",
      "# IMPORTANCE = 'high+'\n",
      "IMPORTANCE = 'med+'\n",
      "\n",
      "#best_params:  {'C': 0.0011973036721303627, 'gamma': 1.1973036721303628e-06, 'class_weight': 'auto'}\n",
      "\n",
      "PARAM_C = 0.0011973036721303627\n",
      "PARAM_GAMMA = 1.1973036721303628e-06"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def eval_clf(clf, X, Y, verbose=True, title=False):\n",
      "    Y_predict = clf.predict(X)\n",
      "    \n",
      "    f1 = metrics.f1_score(Y, Y_predict)\n",
      "    accuracy = metrics.accuracy_score(Y, Y_predict)\n",
      "    precision = metrics.precision_score(Y, Y_predict)\n",
      "    recall = metrics.recall_score(Y, Y_predict)\n",
      "    confusion = metrics.confusion_matrix(Y, Y_predict)\n",
      "    \n",
      "    if verbose:\n",
      "        if title:\n",
      "            print title\n",
      "            print\n",
      "        print 'F1:', f1\n",
      "        print 'accuracy:', accuracy\n",
      "        print 'precision:', precision\n",
      "        print 'recall:', recall\n",
      "        print 'confusion matrix'\n",
      "        print  confusion\n",
      "        print\n",
      "        print metrics.classification_report(Y, Y_predict)\n",
      "    \n",
      "    return {'f1': f1, 'accuracy':accuracy,\n",
      "            'precision': precision, 'recall': recall,\n",
      "            'confusion': confusion}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preprocessing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_commits = commit_postprocessing(PROJECT, importance=IMPORTANCE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading bug data\n",
        "  total LP bugs:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1381\n",
        "  Entries annotated: 536\n",
        "loading Git commit data\n",
        "  total git_commits:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7429\n",
        "  bug fix commits: 1341\n",
        "  commits with change_id: 4011\n",
        "  bug fix with change_id: 1341\n",
        "loading change data\n",
        "  total gerrit changes with detail:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4082\n",
        "  all_change_details: 4082\n",
        "  total gerrit changes:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4084\n",
        "  all_changes: 4084\n",
        "combined_commits:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7429\n",
        "Determining legacy cut-off\n",
        "  Warning: Transition Overlap: 174 days, 7:48:19\n",
        "  Setting cutoff to: 12/11/2012\n",
        "Collecting data on commits with bug fixes\n",
        "  Mainline Commits ignored due to legacy:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 995  out of: 4434\n",
        "  Total commite requiring blame computation: 1110\n",
        "\n",
        "Computing Blame\n",
        "Loaded blame"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Initial Blame cache size: 935\n",
        "  bug fix commits: 1110\n",
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . 100 . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . 200 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". 300 . . . . . . . . . . 400 . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . 500 . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 600 . . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". 700 . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". 800 . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 900 . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . 1000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . 1100 .\n",
        "  Saving updated Blame Cache\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Annotating Guilt\n",
        "Identify reachable commits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Loaded cached reachability data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Initial Reachable cache size: 139\n",
        "  Samples: 139\n",
        "  Revised samples:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "\n",
        "  Reachable commits: 2928\n",
        "Order range for non-legacy comits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  min: 387\n",
        "  max: 2925\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "legacy_cutoff = find_legacy_cutoff(combined_commits)\n",
      "min_order, max_order = get_commit_ordering_min_max(combined_commits)\n",
      "actual_bugs =  compute_selected_bug_fixes(combined_commits, legacy_cutoff=legacy_cutoff,\n",
      "                                          min_order=min_order, max_order=max_order)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Validate number of Bug Fix related commits"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "bug_fix_commits = [k for k,v in combined_commits.items()\n",
      "                   if filter_bug_fix_combined_commits(v, importance=IMPORTANCE)]\n",
      "\n",
      "bug_fix_commits2 = [be['cid'] for be in all_blame\n",
      "                    if filter_bug_fix_combined_commits(combined_commits[be['cid']], \n",
      "                                                       importance=IMPORTANCE)]\n",
      "actual_bugs = len(bug_fix_commits)\n",
      "print 'Bug Fix Commits:', len(bug_fix_commits), '(method 1)', len(bug_fix_commits), '(method 2)', "
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Compute Guilt and Select Threshold Value"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "compute_guilt(combined_commits, importance=IMPORTANCE)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "guilt_threshold, labeled_bugs = autoset_threshold(combined_commits, actual_bugs)\n",
      "print 'Setting guilt threshold to:', guilt_threshold\n",
      "print 'Labeled bugs:', labeled_bugs, ' vs Actual bugs:', actual_bugs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Setting guilt threshold to: 0.261860072385\n",
        "Labeled bugs: 837  vs Actual bugs: 837\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extract_state = fit_features(combined_commits, min_order=min_order, max_order=max_order)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Sliding Window Prediction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def window_predict(combined_commits, guilt_threshold,\n",
      "                   offset, history=500, future=100,\n",
      "                   C=1.0, gamma=0.0,\n",
      "                   tune_threshold=False, tune_threshold_granularity=1,\n",
      "                   decay=False, decay_factor=100.0):\n",
      "    \n",
      "    # get training set based on history\n",
      "    cid, Y_t, X_t, col_names = extract_features(combined_commits,\n",
      "                                                extract_state, \n",
      "                                                min_order=offset-history, max_order=offset-1,\n",
      "                                                threshold=guilt_threshold, debug=False)\n",
      "    # get features for future\n",
      "    _, Y_f, X_f, _ = extract_features(combined_commits,\n",
      "                                      extract_state, \n",
      "                                      min_order=offset, max_order=offset+future-1,\n",
      "                                      threshold=guilt_threshold, debug=False)\n",
      "    \n",
      "    # make sure this is a valid training set\n",
      "    if True not in Y_t or False not in Y_t:\n",
      "        return np.array([[0,0],[0,0]])\n",
      "\n",
      "    if False:  # decay:    # no way to express weight for individual nectors in SVC\n",
      "        # Compute decays based on distance\n",
      "        pos_count = sum([1.0 for v in Y_t if v])\n",
      "        neg_count = sum([1.0 for v in Y_t if not v])\n",
      "        pos_weight = neg_count/ pos_count\n",
      "        \n",
      "        weights = [(2.0 **(float(combined_commits[cid[i]]['order'] - offset +1 )\n",
      "                           / decay_factor)\n",
      "                    * ((not Y_t[i] and 1.0) or (Y_t[i] and pos_weight)))\n",
      "                   for i in range(0, Y_t.size)]\n",
      "    \n",
      "        clf = SVC(C=C, gamma=gamma, class_weight='auto')  # no way to pass individual weights.\n",
      "    else:\n",
      "        clf = SVC(C=C, gamma=gamma, class_weight='auto')\n",
      "\n",
      "    clf.fit(X_t, Y_t)    # train model based on historical data\n",
      "\n",
      "    if tune_threshold:\n",
      "        # use training set to optimize decision boundary threshold setting\n",
      "        probs = clf.decision_function(X_t)\n",
      "        best_f1 = -1.0\n",
      "        best_threshold = -1\n",
      "        for i in range(-200, 201, tune_threshold_granularity):\n",
      "            threshold = float(i)/1000.0\n",
      "            predict = probs >= threshold        \n",
      "            f1 = metrics.f1_score(Y_t, predict)\n",
      "        \n",
      "            if f1 > best_f1:\n",
      "                best_f1 = f1\n",
      "                best_threshold = threshold\n",
      " \n",
      "        # print 'Using threshold:', best_threshold\n",
      "        probs = clf.decision_function(X_f)\n",
      "        predict_future = probs >= best_threshold        \n",
      "    else:\n",
      "        predict_future = clf.predict(X_f)\n",
      "\n",
      "    # Return quality of future predictions       \n",
      "    cm = metrics.confusion_matrix(Y_f, predict_future)    \n",
      "    return cm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_multiple_windows(combined_commits, guilt_threshold,\n",
      "                          starting_offset=0, ending_offset=0, iter=2,\n",
      "                          history=500, future=100, C=1.0, gamma=0.0,\n",
      "                          tune_threshold=False, tune_threshold_granularity=1,\n",
      "                          min_order=False, max_order=False):\n",
      "    \n",
      "    # TO DO:  Fix to use threhsold value \n",
      "    \n",
      "    if not min_order:\n",
      "        min_order = min([c['order'] for c in combined_commits.values()])\n",
      "    if not max_order:\n",
      "        max_order = max([c['order'] for c in combined_commits.values()])\n",
      "    \n",
      "    lower = min_order + starting_offset\n",
      "    upper = max_order - future + 1 - ending_offset\n",
      "    \n",
      "    result = np.array([[0,0],[0,0]])\n",
      "    for i in np.random.randint(lower, upper, size=iter):\n",
      "        cm =  window_predict(combined_commits, guilt_threshold, i, \n",
      "                             C=C, gamma=gamma,      \n",
      "                             tune_threshold=tune_threshold,\n",
      "                             tune_threshold_granularity=tune_threshold_granularity)\n",
      "        result += cm\n",
      "\n",
      "    try:    \n",
      "        precision = float(result[1,1]) / float(result[0,1] + result[1,1])\n",
      "    except Exception:\n",
      "        precision = 'NaN'\n",
      "        \n",
      "    try: \n",
      "        recall = float(result[1,1]) / float(result[1,0] + result[1,1])\n",
      "    except Exception:\n",
      "        recall = 'NaN'\n",
      "        \n",
      "    try: \n",
      "        f1 = (2.0*precision*recall)/(precision+recall)\n",
      "    except Exception:\n",
      "        f1 = 'NaN'\n",
      "        \n",
      "    return {'f1': f1, 'precision': precision, 'recall': recall, 'cm': result}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "test_multiple_windows(combined_commits, guilt_threshold, iter=10,\n",
      "                         C=PARAM_C, gamma=PARAM_GAMMA, min_order=min_order, max_order=max_order)\n",
      "test_multiple_windows(combined_commits, guilt_threshold, iter=10, tune_threshold=True,\n",
      "                         C=PARAM_C, gamma=PARAM_GAMMA, min_order=min_order, max_order=max_order)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def my_grid_search(combined_commits, guilt_threshold,\n",
      "                   iter=1, future=50, C=1.0, gamma=0.0, \n",
      "                   history_sizes=[75, 100, 133, 150, 166, 200, 250, 300, 400, 500],\n",
      "                   tune_params=[False, True],\n",
      "                   min_order=False, max_order=False):\n",
      "    \n",
      "    max_hist = max(history_sizes)\n",
      "    results = []\n",
      "    for tune in tune_params:\n",
      "        for hist in history_sizes:\n",
      "            print '.', \n",
      "            entry = test_multiple_windows(combined_commits, guilt_threshold,\n",
      "                          starting_offset=max_hist-hist, iter=iter,\n",
      "                          history=hist, future=future, C=C, gamma=gamma, tune_threshold=tune,\n",
      "                          min_order=min_order, max_order=max_order)\n",
      "            entry['history'] = hist\n",
      "            entry['future'] = future\n",
      "            entry['tune'] = tune\n",
      "            entry['C'] = C\n",
      "            entry['gamma'] = gamma\n",
      "            results.append(entry)\n",
      "    print\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "results = my_grid_search(combined_commits, guilt_threshold,\n",
      "                         iter=50, future=50, C=PARAM_C, gamma=PARAM_GAMMA, min_order=min_order, max_order=max_order)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results2 = my_grid_search(combined_commits, guilt_threshold,\n",
      "                          iter=50, future=100, C=PARAM_C, gamma=PARAM_GAMMA, min_order=min_order, max_order=max_order)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/doug/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "results3 = my_grid_search(combined_commits, guilt_threshold,\n",
      "                          iter=50, future=75, C=PARAM_C, gamma=PARAM_GAMMA, min_order=min_order, max_order=max_order)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "results4 = my_grid_search(combined_commits, guilt_threshold,\n",
      "                          iter=50, future=150, C=PARAM_C, gamma=PARAM_GAMMA, min_order=min_order, max_order=max_order)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results5 = my_grid_search(combined_commits, guilt_threshold,\n",
      "                          iter=50, future=200, C=PARAM_C, gamma=PARAM_GAMMA, min_order=min_order, max_order=max_order)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ".\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# all_results = results + results2 + results3 + results4 + results5\n",
      "all_results =  results2 + results5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_results = sorted(all_results, key=lambda x: x['f1'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Look at best results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_results[-3:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "[{'C': 0.0011973036721303627, 'cm': array([[1534, 2156],\n",
        "         [ 446,  864]]), 'f1': 0.3990762124711316, 'future': 200, 'gamma': 1.1973036721303628e-06, 'history': 100, 'precision': 0.2860927152317881, 'recall': 0.6595419847328244, 'tune': False},\n",
        " {'C': 0.0011973036721303627, 'cm': array([[1747, 1882],\n",
        "         [ 553,  818]]), 'f1': 0.4018668631785802, 'future': 200, 'gamma': 1.1973036721303628e-06, 'history': 166, 'precision': 0.302962962962963, 'recall': 0.5966447848285923, 'tune': True},\n",
        " {'C': 0.0011973036721303627, 'cm': array([[1794, 1734],\n",
        "         [ 606,  866]]), 'f1': 0.4253438113948919, 'future': 200, 'gamma': 1.1973036721303628e-06, 'history': 150, 'precision': 0.3330769230769231, 'recall': 0.5883152173913043, 'tune': False}]"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from jp_load_dump import pload, pdump "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pdump(all_results, 'blame_analysis_results.p')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Boneyard"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Can we use below code to compute a bias value to maximize F1 ?"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "def bar(clf, X, Y, threshold=0.5):\n",
      "    print 'Input Labels'\n",
      "    print metrics.confusion_matrix(Y, Y)\n",
      "    print\n",
      "    print 'Baseline F1:', \n",
      "    predict = clf.predict(X)       \n",
      "    f1 = metrics.f1_score(Y, predict)\n",
      "    print f1\n",
      "    print metrics.confusion_matrix(Y, predict)\n",
      "    print\n",
      "    probs = clf.decision_function(X)\n",
      "    #f1 = metrics.f1_score(Y, y_predict)\n",
      "    \n",
      "    best_f1 = -1.0\n",
      "    best_threshold = -1\n",
      "    for i in range(-200, 201, 1):\n",
      "        threshold = float(i)/1000.0\n",
      "        predict = probs >= threshold        \n",
      "        f1 = metrics.f1_score(Y, predict)\n",
      "        \n",
      "        if f1 > best_f1:\n",
      "            best_f1 = f1\n",
      "            best_threshold = threshold\n",
      "        \n",
      "    threshold = best_threshold\n",
      "    predict = probs >= threshold        \n",
      "    f1 = metrics.f1_score(Y, predict)\n",
      "        \n",
      "    print threshold, ':', \n",
      "    print f1\n",
      "    print metrics.confusion_matrix(Y, predict)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "bar(clf, X_predict_vshort, Y_predict_vshort)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}