{
 "metadata": {
  "name": "",
  "signature": "sha256:5237c03203e9db709c50c037e45e068c070ade6b846265cb56275879eb2547e5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Blame Analysis for OpenStack Projects\n",
      "\n",
      "Copyright Doug Williams - 2014, 2015\n",
      "\n",
      "###Updated: 2/7/2015\n",
      "\n",
      "###General Approach:\n",
      "\n",
      "####Generate Guilt (raw data for labels)\n",
      "- Create wrapper around extend blame_compute_normalized_guilt() to compute cumulative blame for a commit\n",
      "- Apply thresholding to deterime which commits get labelled as bug contributors\n",
      " \n",
      "####Generate Features\n",
      "Current Features:\n",
      "- author, author's org\n",
      "- list of files changed\n",
      "- review stats\n",
      "- ordering info (expressed as log of order):\n",
      " - Author order\n",
      " - Include max and min order for files (overall and by author)\n",
      " - Include order by individual files\n",
      "- Overall change complexity and degree of change by individual files\n",
      "- If this is a fix to an existing bug\n",
      "\n",
      "Others to consider in future::\n",
      "- information on reviewer or committer experience?\n",
      " - express as reviewer order\n",
      "- prior bugs by file\n",
      "- prior bugs by author\n",
      "\n",
      "####Train model\n",
      "To Do:\n",
      " - Plot Learning Curves"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Proposed approach for equalization:\n",
      "\n",
      "- Method 1: Delete False entries until target percentage achieved\n",
      "- Method 2: Duplicate True entries until target percentage achieved\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###History\n",
      "- 1/28/2015: Initial file creation, derived from NovaSampleData\n",
      "- 1/29/2015:  Shift to use of Swift for initial analysis\n",
      "- 1/30/2015:  First pass end-to end analysis complete using SVM, including create_feature() and extract_features. Recall 0.78, F1 0.88, however very sensitive to training set size.\n",
      "\n",
      "###Issues:\n",
      "- SVM results extremely sensitive to training set size (fails if > 100)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Includes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pprint import pprint\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "import numpy as np\n",
      "import math\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from sklearn.cross_validation import ShuffleSplit\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import metrics\n",
      "\n",
      "# from sklearn.feature_extraction import DictVectorizer\n",
      "# from sklearn.preprocessing import StandardScaler\n",
      "# from sklearn.preprocessing import MinMaxScaler\n",
      "# from sklearn.svm import SVR\n",
      "\n",
      "import sys\n",
      "sys.path.append('./dev')\n",
      "\n",
      "from Git_Extract_Join import  filter_bug_fix_combined_commits\n",
      "\n",
      "from commit_analysis import load_core_analysis_data\n",
      "from commit_analysis import extract_features\n",
      "from commit_analysis import compute_guilt\n",
      "\n",
      "# from commit_analysis import blame_compute_normalized_guilt\n",
      "# from commit_analysis import normalize_blame_by_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Configuration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PROJECT = 'nova'\n",
      "# PROJECT = 'swift'\n",
      "# PROJECT = 'cinder'\n",
      "# PROJECT = 'heat'\n",
      "PROJECT = 'glance'\n",
      "\n",
      "IMPORTANCE = 'high+'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Threshold Values based on Blame curves:\n",
      "\n",
      "Set threshold value so that number of True labels roughly matches bug count\n",
      "- Heat: 0.165\n",
      "- Cinder: 0.0675\n",
      "- Glance: 0.155\n",
      "- Swift: 0.15\n",
      "- Nova: 0.162"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thresholds = { \n",
      "'high+': {\n",
      "    'nova': 0.162, \n",
      "    'swift': 0.15,\n",
      "    'cinder': 0.0675,\n",
      "    'heat': 0.165,\n",
      "    'glance': 0.155,\n",
      "    },\n",
      "}\n",
      "\n",
      "guilt_threshold = thresholds[IMPORTANCE][PROJECT]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Processing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_commits, all_blame = load_core_analysis_data(PROJECT)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "combined_commits: 4076\n",
        "all blame:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1715\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bug_fix_commits = [k for k,v in combined_commits.items()\n",
      "                   if filter_bug_fix_combined_commits(v, importance=IMPORTANCE)]\n",
      "print len(bug_fix_commits)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "438\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Compute Guilt"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "compute_guilt(combined_commits, all_blame, importance=IMPORTANCE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "guilty:  1294 out of 4076 ( 31.7468105986 % )\n",
        "smallest guilt: 9.49216896061e-05\n",
        "largest guilt: 7.03667698766\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Feature Extraction and Preprocessing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cid, Y, X, col_names = extract_features(combined_commits, all_blame, threshold=guilt_threshold)\n",
      "print\n",
      "print X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total features: 3957\n",
        "bugs based on threshold: 420\n",
        "actual bugs: 1714\n",
        "\n",
        "(3957, 2496)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Proposed enhancements to training\n",
      "\n",
      "Some speculative thoughts:\n",
      "- Feature Extraction Test/Train\n",
      " - Separately extract features for test/train period, skip latest 20% of commits\n",
      " - Change balance of positive/negative commits to imprpve trainging.  Traioning currently skewed towards negative test vased today\n",
      "- Create validation test suite with latest tests.  Want to measure prediction accuracy for future bugs."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "from sklearn.decomposition import PCA\n",
      "\n",
      "# Note:  Weakness in methodology, really should fix using training set only\n",
      "\n",
      "pca = PCA(n_components='mle')\n",
      "X = pca.fit_transform(X)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Train SVM Classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Train classifier\n",
      "\n",
      "C_range = 10.0 ** np.arange(-2, 9)\n",
      "gamma_range = 10.0 ** np.arange(-5, 4)\n",
      "param_grid = dict(gamma=gamma_range, C=C_range)\n",
      "\n",
      "# cv = StratifiedKFold(y=Y, n_folds=3)\n",
      "# cv = StratifiedShuffleSplit(Y, train_size=0.2, test_size=0.2, random_state=0)\n",
      "\n",
      "cv = StratifiedShuffleSplit(Y, train_size=100,\n",
      "                            test_size=100, random_state=0)\n",
      "# cv = ShuffleSplit(len(Y), train_size=100, test_size=100, random_state=0)\n",
      "\n",
      "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=cv,\n",
      "                    n_jobs=4, pre_dispatch=8) # verbose=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "GridSearchCV(cv=StratifiedShuffleSplit(labels=[False  True ..., False False], n_iter=10, test_size=100, random_state=0),\n",
        "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
        "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=4,\n",
        "       param_grid={'C': array([  1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
        "         1.00000e+02,   1.00000e+03,   1.00000e+04,   1.00000e+05,\n",
        "         1.00000e+06,   1.00000e+07,   1.00000e+08]), 'gamma': array([  1.00000e-05,   1.00000e-04,   1.00000e-03,   1.00000e-02,\n",
        "         1.00000e-01,   1.00000e+00,   1.00000e+01,   1.00000e+02,\n",
        "         1.00000e+03])},\n",
        "       pre_dispatch=8, refit=True, score_func=None, scoring=None,\n",
        "       verbose=0)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"The best classifier is: \", grid.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The best classifier is:  SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
        "  gamma=1.0000000000000001e-05, kernel='rbf', max_iter=-1,\n",
        "  probability=False, random_state=None, shrinking=True, tol=0.001,\n",
        "  verbose=False)\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'best_score: ', grid.best_score_\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best_score:  0.89\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'best_params: ',\n",
      "print grid.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best_params:  {'C': 0.01, 'gamma': 1.0000000000000001e-05}\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = grid.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
        "  gamma=1.0000000000000001e-05, kernel='rbf', max_iter=-1,\n",
        "  probability=False, random_state=None, shrinking=True, tol=0.001,\n",
        "  verbose=False)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.fit(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0, degree=3,\n",
        "  gamma=1.0000000000000001e-05, kernel='rbf', max_iter=-1,\n",
        "  probability=False, random_state=None, shrinking=True, tol=0.001,\n",
        "  verbose=False)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Score:\", clf.score(X, Y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Score: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.893858984079\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print\n",
      "Y_predict = clf.predict(X)\n",
      "print 'F1:', metrics.f1_score(Y, Y_predict)\n",
      "print 'accuracy:', metrics.accuracy_score(Y, Y_predict)\n",
      "print 'precision:', metrics.precision_score(Y, Y_predict)\n",
      "print 'recall:', metrics.recall_score(Y, Y_predict)\n",
      "print metrics.confusion_matrix(Y, Y_predict)\n",
      "print\n",
      "print metrics.classification_report(Y, Y_predict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "F1:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0\n",
        "accuracy: 0.893858984079\n",
        "precision: 0.0\n",
        "recall: 0.0\n",
        "[[3537    0]\n",
        " [ 420    0]]\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.89      1.00      0.94      3537\n",
        "       True       0.00      0.00      0.00       420\n",
        "\n",
        "avg / total       0.80      0.89      0.84      3957\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/doug/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n",
        "/Users/doug/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n",
        "/Users/doug/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:1771: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
        "  'precision', 'predicted', average, warn_for)\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X.shape\n",
      "print X[1:100,].shape\n",
      "print np.concatenate((X, X), axis=0).shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3957, 2496)\n",
        "(99, 2496)\n",
        "(7914, 2496)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Boneyard"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "cid, y, X, col_names = extract_features(combined_commits, all_blame, clip=2.0)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "# Train cRegression classifier\n",
      "\n",
      "C_range = 10.0 ** np.arange(-2, 9)\n",
      "gamma_range = 10.0 ** np.arange(-5, 4)\n",
      "param_grid = dict(gamma=gamma_range, C=C_range)\n",
      "\n",
      "# cv = StratifiedKFold(y=Y, n_folds=3)\n",
      "# cv = StratifiedShuffleSplit(Y, train_size=0.2, test_size=0.2, random_state=0)\n",
      "\n",
      "#cv = StratifiedShuffleSplit(Y, train_size=100, test_size=100, random_state=0)\n",
      "cv = ShuffleSplit(len(Y), train_size=100, test_size=100, random_state=0)\n",
      "\n",
      "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
      "grid.fit(X, Y)\n",
      "\n",
      "print \"The best classifier is: \", grid.best_estimator_\n",
      "print\n",
      "clf = grid.best_estimator_\n",
      "print \"Score:\", clf.score(X, Y)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "YY = clf.predict(X)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "for i in range(100):\n",
      "    print abs(y[i] - YY[i])\n",
      "        # , '    ',  y[i], '    ', YY[i]"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "from random import randint"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "def shuffle(idx, iter=10):\n",
      "    \"\"\"Shuffles an array of values.\n",
      "    idx - can be a list, array or an integer.  If integer,\n",
      "    initialized as an array from 0 to n-1.\n",
      "    \"\"\"\n",
      "    if type(idx) is list:\n",
      "        pass\n",
      "    elif type(idx) is int:\n",
      "        idx = range(idx)\n",
      "    else:\n",
      "        raise Exception('shuffle: Invalid index type')\n",
      "    \n",
      "    elements = len(idx)\n",
      "    for n in range(iter):\n",
      "        for i in range(elements):\n",
      "            x = randint(0, elements - 1)\n",
      "            idx[i], idx[x] = idx[x], idx[i]   # swap\n",
      "    return idx"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shuffle(20, iter=10000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'shuffle' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-20-e4d5db1128ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'shuffle' is not defined"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}