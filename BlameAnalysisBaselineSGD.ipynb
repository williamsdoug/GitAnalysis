{
 "metadata": {
  "name": "",
  "signature": "sha256:17768ec487d22f83d84207642aa6168edd32f99e78c0fa00225ac53a8f7fbe13"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Baseline Blame Analysis for OpenStack Projects using Gradient Descent\n",
      "\n",
      "Copyright Doug Williams - 2014, 2015\n",
      "\n",
      "###Updated: 3/12/2015\n",
      "\n",
      "###References:\n",
      "- http://research.microsoft.com/pubs/192769/tricks-2012.pdf\n",
      "\n",
      "###Currently best patrams:\n",
      "\n",
      "best_params:  {'n_iter': 100, 'eta0': 0.5, 'shuffle': True, 'loss': 'perceptron', 'learning_rate': 'optimal', 'alpha': 0.0001, 'class_weight': 'auto'}\n",
      "\n",
      "###Result:\n",
      "\n",
      "####Heat:\n",
      "- F1: 0.792546583851\n",
      "- accuracy: 0.833166833167\n",
      "- precision: 0.738425925926\n",
      "- recall: 0.855227882038\n",
      "- confusion matrix\n",
      " - [[515 113]\n",
      " -  [ 54 319]]"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Includes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pprint import pprint\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "import numpy as np\n",
      "import math\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "#from sklearn.svm import SVC\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.cross_validation import StratifiedKFold\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "from sklearn.cross_validation import ShuffleSplit\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import metrics\n",
      "\n",
      "# from sklearn.feature_extraction import DictVectorizer\n",
      "# from sklearn.preprocessing import StandardScaler\n",
      "#from sklearn.preprocessing import MinMaxScaler\n",
      "# from sklearn.svm import SVR\n",
      "\n",
      "import sys\n",
      "sys.path.append('./dev')\n",
      "\n",
      "from Git_Extract import get_commit_ordering_min_max\n",
      "from commit_analysis import fit_features\n",
      "from commit_analysis import extract_features\n",
      "from commit_analysis import autoset_threshold\n",
      "from BugFixWorkflow import compute_selected_bug_fixes\n",
      "from BugFixWorkflow import commit_postprocessing\n",
      "from BugFixWorkflow import find_legacy_cutoff"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Configuration"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Dataset Selection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PROJECT = 'nova'\n",
      "# PROJECT = 'swift'\n",
      "# PROJECT = 'cinder'\n",
      "PROJECT = 'heat'\n",
      "# PROJECT = 'glance'\n",
      "\n",
      "# IMPORTANCE = 'crit'\n",
      "# IMPORTANCE = 'high+'\n",
      "IMPORTANCE = 'med+'\n",
      "# IMPORTANCE = 'low+'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Training Parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# SIZE = 100\n",
      "#SIZE = 250\n",
      "# SIZE = 0.1\n",
      "SIZE = 0.5\n",
      "\n",
      "SCORING = 'f1'         # (precision * recall) / (precision + recall)\n",
      "# SCORING = 'accuracy'   # (TP + TN) / all values\n",
      "# SCORING = 'precision'  # TP / (TP + FP)\n",
      "# SCORING = 'recall'     # TP / (TP + FN)\n",
      "# SCORING = 'average_precision'\n",
      "# SCORING = 'roc_auc'\n",
      "\n",
      "JOBS = 4\n",
      "\n",
      "VERBOSE = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def eval_clf(clf, X, Y, verbose=True, title=False):\n",
      "    Y_predict = clf.predict(X)\n",
      "    \n",
      "    f1 = metrics.f1_score(Y, Y_predict)\n",
      "    accuracy = metrics.accuracy_score(Y, Y_predict)\n",
      "    precision = metrics.precision_score(Y, Y_predict)\n",
      "    recall = metrics.recall_score(Y, Y_predict)\n",
      "    confusion = metrics.confusion_matrix(Y, Y_predict)\n",
      "    \n",
      "    if verbose:\n",
      "        if title:\n",
      "            print title\n",
      "            print\n",
      "        print 'F1:', f1\n",
      "        print 'accuracy:', accuracy\n",
      "        print 'precision:', precision\n",
      "        print 'recall:', recall\n",
      "        print 'confusion matrix'\n",
      "        print  confusion\n",
      "        print\n",
      "        print metrics.classification_report(Y, Y_predict)\n",
      "    \n",
      "    return {'f1': f1, 'accuracy':accuracy,\n",
      "            'precision': precision, 'recall': recall,\n",
      "            'confusion': confusion}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Preprocessing"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_commits = commit_postprocessing(PROJECT, importance=IMPORTANCE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading bug data\n",
        "  total LP bugs:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1388\n",
        "  Entries annotated: 536\n",
        "loading Git commit data\n",
        "  total git_commits:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7566\n",
        "  bug fix commits: 1353\n",
        "  commits with change_id: 4084\n",
        "  bug fix with change_id: 1353\n",
        "loading change data\n",
        "  total gerrit changes with detail:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4126\n",
        "  all_change_details: 4126\n",
        "  total gerrit changes:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 4132\n",
        "  all_changes: 4132\n",
        "combined_commits:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 7566\n",
        "Determining legacy cut-off\n",
        "  Warning: Transition Overlap: 174 days, 7:48:19\n",
        "  Setting cutoff to: 12/11/2012\n",
        "Collecting data on commits with bug fixes\n",
        "  Mainline Commits ignored due to legacy:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 995  out of: 4507\n",
        "  Total commite requiring blame computation: 1113\n",
        "\n",
        "Computing Blame\n",
        "Loaded blame"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Initial Blame cache size: 939\n",
        "  bug fix commits: 1113\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . 100 . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". 200 . . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . 300 . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . . . . 400 . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . 500 . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . 600 . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . 700 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . 800 . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". 900 . . . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . 1000 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . . . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 1100 .\n",
        "  Saving updated Blame Cache\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Annotating Guilt\n",
        "entries with non-zero guilt: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 1668\n",
        "smallest guilt: 0.000256278831369\n",
        "largest guilt: 36.2464850617\n",
        "Identify reachable commits\n",
        "  Loaded cached reachability data"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Initial Reachable cache size: 142\n",
        "  Samples: 142\n",
        "  Revised samples:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0\n",
        "\n",
        "  Reachable commits: 2975\n",
        "Annotating lines of code changed\n",
        "  Loaded Lines of Code Changed cache"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  Initial Lines of Code Changed cache size: 2972\n",
        ". . . . . . . . . . 1000 . . . . . . . . . . 2000 . . . . . . . . .\n",
        "Order range for non-legacy comits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "  min: 387\n",
        "  max: 2972\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Autoconfigure Dataset\n",
      "- Identify non-legacy commits\n",
      "- Set threshold for guilty commits"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "legacy_cutoff = find_legacy_cutoff(combined_commits)\n",
      "min_order, max_order = get_commit_ordering_min_max(combined_commits)\n",
      "actual_bugs =  compute_selected_bug_fixes(combined_commits, legacy_cutoff=legacy_cutoff,\n",
      "                                          min_order=min_order, max_order=max_order)\n",
      "guilt_threshold, labeled_bugs = autoset_threshold(combined_commits, actual_bugs)\n",
      "print 'Setting guilt threshold to:', guilt_threshold\n",
      "print 'Labeled bugs:', labeled_bugs, ' vs Actual bugs:', actual_bugs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Setting guilt threshold to: 0.262413145944\n",
        "Labeled bugs: 840  vs Actual bugs: 840\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Feature Extraction and Creation of Training Sets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Steps:\n",
      "- Generate full dataset for use in training scaler\n",
      " - Train scaler\n",
      "- Generate Train/Test Dataset\n",
      "- Generate prediction dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "extract_state = fit_features(combined_commits, min_order=min_order, max_order=max_order)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total features: 2374\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "_, Y_train, X_train, col_names = extract_features(combined_commits,\n",
      "                                                  extract_state, \n",
      "                                                  min_order=500, max_order=1500,\n",
      "                                                  threshold=guilt_threshold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total feature vectors: 1001\n",
        "  bugs based on threshold: 373\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cid_predict_vshort, Y_predict_vshort, \\\n",
      "X_predict_vshort, col_names = extract_features(combined_commits,\n",
      "                                               extract_state,\n",
      "                                               min_order=1501, max_order=1550,\n",
      "                                               threshold=guilt_threshold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total feature vectors: 50\n",
        "  bugs based on threshold: 19\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cid_predict_short, Y_predict_short, \\\n",
      "X_predict_short, col_names = extract_features(combined_commits,\n",
      "                                              extract_state,\n",
      "                                              min_order=1501, max_order=1600,\n",
      "                                              threshold=guilt_threshold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total feature vectors: 100\n",
        "  bugs based on threshold: 27\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cid_predict_med, Y_predict_med,\\\n",
      "X_predict_med, col_names = extract_features(combined_commits,\n",
      "                                            extract_state,\n",
      "                                            min_order=1501, max_order=1700,\n",
      "                                            threshold=guilt_threshold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total feature vectors: 200\n",
        "  bugs based on threshold: 71\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cid_predict_long, Y_predict_long, \\\n",
      "X_predict_long, col_names = extract_features(combined_commits,\n",
      "                                             extract_state,\n",
      "                                             min_order=1501, max_order=2000,\n",
      "                                             threshold=guilt_threshold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total feature vectors: 500\n",
        "  bugs based on threshold: 144\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if True:\n",
      "    cid_predict_vlong, Y_predict_vlong, \\\n",
      "    X_predict_vlong, col_names = extract_features(combined_commits,\n",
      "                                              extract_state,\n",
      "                                              min_order=1501,\n",
      "                                              max_order=max_order,\n",
      "                                              threshold=guilt_threshold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total feature vectors: 1472\n",
        "  bugs based on threshold: 275\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Proposed enhancements to training\n",
      "\n",
      "Some speculative thoughts:\n",
      "- Feature Extraction Test/Train\n",
      " - Separately extract features for test/train period, skip latest 20% of commits\n",
      " - Change balance of positive/negative commits to imprpve trainging.  Traioning currently skewed towards negative test vased today\n",
      "- Create validation test suite with latest tests.  Want to measure prediction accuracy for future bugs."
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "from sklearn.decomposition import PCA\n",
      "\n",
      "# Note:  Weakness in methodology, really should fix using training set only\n",
      "\n",
      "pca = PCA(n_components='mle')\n",
      "X = pca.fit_transform(X)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Classification"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Other classifiers to explore\n",
      "- from sklearn.linear_model import LogisticRegression\n",
      " - clf = LogisticRegression()\n",
      "- sklearn.linear_model.SGDClassifier\n",
      "- sklearn.svm.LinearSVC\n",
      "- sklearn.tree.DecisionTreeClassifier"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "SGD Classifier - Coarse"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "C_range = 10.0 ** np.arange(-2, 9)\n",
      "gamma_range = 10.0 ** np.arange(-5, 4)\n",
      "param_grid = dict(gamma=gamma_range, C=C_range, class_weight=['auto'], \n",
      "                  # probability=[True]\n",
      "                  )\n",
      "\n",
      "grid = GridSearchCV(SGDClassifier(), param_grid=param_grid, cv=cv, scoring=SCORING,\n",
      "                    n_jobs=JOBS, pre_dispatch=2*JOBS, verbose=VERBOSE)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cv = StratifiedKFold(y=Y, n_folds=3)\n",
      "cv = StratifiedShuffleSplit(Y_train, train_size=SIZE, test_size=SIZE, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_iter = np.ceil(10**6 / len(Y_train))  # see rule of thumb in section 1.3.5 of http://scikit-learn.org/stable/modules/sgd.html"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha_range = 10.0 ** np.arange(-7, -1)\n",
      "param_grid = dict(alpha=alpha_range, class_weight=['auto'], \n",
      "                  loss=['hinge', 'log', 'modified_huber', 'perceptron'], #'squared_hinge']\n",
      "                  #eta0=[0.5, 0.1, 0.05, 0.01],\n",
      "                  #learning_rate=['optimal', 'invscaling', 'constant'],\n",
      "                  n_iter=[400], shuffle=[True])\n",
      "\n",
      "grid = GridSearchCV(SGDClassifier(), param_grid=param_grid, cv=cv, scoring=SCORING,\n",
      "                    n_jobs=JOBS, pre_dispatch=2*JOBS,\n",
      "                    verbose=VERBOSE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid.fit(X_train, Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=4)]: Done   1 jobs       | elapsed:    1.0s\n",
        "[Parallel(n_jobs=4)]: Done  50 jobs       | elapsed:   13.4s\n",
        "[Parallel(n_jobs=4)]: Done 200 jobs       | elapsed:   51.0s\n",
        "[Parallel(n_jobs=4)]: Done 234 out of 240 | elapsed:  1.0min remaining:    1.6s\n",
        "[Parallel(n_jobs=4)]: Done 240 out of 240 | elapsed:  1.0min finished\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "GridSearchCV(cv=StratifiedShuffleSplit(labels=[False False ..., False False], n_iter=10, test_size=0.5, random_state=0),\n",
        "       estimator=SGDClassifier(alpha=0.0001, class_weight=None, epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
        "       loss='hinge', n_iter=5, n_jobs=1, penalty='l2', power_t=0.5,\n",
        "       random_state=None, shuffle=False, verbose=0, warm_start=False),\n",
        "       fit_params={}, iid=True, loss_func=None, n_jobs=4,\n",
        "       param_grid={'n_iter': [400], 'loss': ['hinge', 'log', 'modified_huber', 'perceptron'], 'class_weight': ['auto'], 'shuffle': [True], 'alpha': array([  1.00000e-07,   1.00000e-06,   1.00000e-05,   1.00000e-04,\n",
        "         1.00000e-03,   1.00000e-02])},\n",
        "       pre_dispatch=8, refit=True, score_func=None, scoring='f1',\n",
        "       verbose=1)"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"The best classifier is: \", grid.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The best classifier is:  SGDClassifier(alpha=0.01, class_weight='auto', epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
        "       loss='log', n_iter=400, n_jobs=1, penalty='l2', power_t=0.5,\n",
        "       random_state=None, shuffle=True, verbose=0, warm_start=False)\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'best_params: ',\n",
      "print grid.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best_params:  {'n_iter': 400, 'alpha': 0.01, 'loss': 'log', 'shuffle': True, 'class_weight': 'auto'}\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'best_score: ', grid.best_score_\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "best_score:  0.507444483382\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = grid.best_estimator_\n",
      "clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "SGDClassifier(alpha=0.01, class_weight='auto', epsilon=0.1, eta0=0.0,\n",
        "       fit_intercept=True, l1_ratio=0.15, learning_rate='optimal',\n",
        "       loss='log', n_iter=400, n_jobs=1, penalty='l2', power_t=0.5,\n",
        "       random_state=None, shuffle=True, verbose=0, warm_start=False)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eval_clf(clf, X_train, Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F1: 0.671755725191\n",
        "accuracy: 0.742257742258\n",
        "precision: 0.639225181598\n",
        "recall: 0.707774798928\n",
        "confusion matrix\n",
        "[[479 149]\n",
        " [109 264]]\n",
        "\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.81      0.76      0.79       628\n",
        "       True       0.64      0.71      0.67       373\n",
        "\n",
        "avg / total       0.75      0.74      0.74      1001\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "{'accuracy': 0.74225774225774221, 'confusion': array([[479, 149],\n",
        "        [109, 264]]), 'f1': 0.6717557251908397, 'precision': 0.63922518159806296, 'recall': 0.70777479892761397}"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Train SGD Classifier - Fine"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "C = grid.best_params_['C']\n",
      "gamma = grid.best_params_['gamma']\n",
      "\n",
      "C_range = C * 1.7 ** np.arange(-4, 5)\n",
      "gamma_range = gamma * 1.7 ** np.arange(-4, 5)\n",
      "\n",
      "print C, C_range\n",
      "print gamma, gamma_range"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha = grid.best_params_['alpha']\n",
      "loss = grid.best_params_['loss']\n",
      "#learning_rate = grid.best_params_['learning_rate']\n",
      "#eta0 = grid.best_params_['eta0']\n",
      "\n",
      "alpha_range = alpha * 1.7 ** np.arange(-4, 5)\n",
      "param_grid = dict(alpha=alpha_range, class_weight=['auto'], loss=[loss], \n",
      "                  #learning_rate=[learning_rate], \n",
      "                  #eta0=[eta0],\n",
      "                  n_iter=[400], shuffle=[True])\n",
      "\n",
      "grid = GridSearchCV(SGDClassifier(), param_grid=param_grid, cv=cv, scoring=SCORING,\n",
      "                    n_jobs=JOBS, pre_dispatch=2*JOBS, verbose=VERBOSE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid.fit(X_train, Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"The best classifier is: \", grid.best_estimator_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'best_params: ',\n",
      "print grid.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'best_score: ', grid.best_score_\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Evaluate Training Results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = grid.best_estimator_\n",
      "clf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eval_clf(clf, X_train, Y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Now determine predictive value"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'incidence of bugs:',  float(actual_bugs)/ float(len(combined_commits))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eval_clf(clf, X_predict_vshort, Y_predict_vshort)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eval_clf(clf, X_predict_short, Y_predict_short)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eval_clf(clf, X_predict_med, Y_predict_med)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eval_clf(clf, X_predict_long, Y_predict_long)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if True:\n",
      "    eval_clf(clf, X_predict_vlong, Y_predict_vlong)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Boneyard"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Can we use below code to compute a bias value to maximize F1 ?"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "def bar(clf, X, Y, threshold=0.5):\n",
      "    print 'Input Labels'\n",
      "    print metrics.confusion_matrix(Y, Y)\n",
      "    print\n",
      "    print 'Baseline F1:', \n",
      "    predict = clf.predict(X)       \n",
      "    f1 = metrics.f1_score(Y, predict)\n",
      "    print f1\n",
      "    print metrics.confusion_matrix(Y, predict)\n",
      "    print\n",
      "    probs = clf.decision_function(X)\n",
      "    #f1 = metrics.f1_score(Y, y_predict)\n",
      "    \n",
      "    best_f1 = -1.0\n",
      "    best_threshold = -1\n",
      "    for i in range(-200, 201, 1):\n",
      "        threshold = float(i)/1000.0\n",
      "        predict = probs >= threshold        \n",
      "        f1 = metrics.f1_score(Y, predict)\n",
      "        \n",
      "        if f1 > best_f1:\n",
      "            best_f1 = f1\n",
      "            best_threshold = threshold\n",
      "        \n",
      "    threshold = best_threshold\n",
      "    predict = probs >= threshold        \n",
      "    f1 = metrics.f1_score(Y, predict)\n",
      "        \n",
      "    print threshold, ':', \n",
      "    print f1\n",
      "    print metrics.confusion_matrix(Y, predict)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "bar(clf, X_predict_vshort, Y_predict_vshort)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "def foo(clf, X, Y, threshold=0.5):\n",
      "    print clf.classes_\n",
      "    print\n",
      "    predict = clf.predict(X)\n",
      "    probs = clf.predict_proba(X)\n",
      "    \n",
      "    for i in range(Y.size):\n",
      "        if Y[i] != predict[i]:\n",
      "            print Y[i], predict[i], probs[i][0] - probs[i][1], '     ', probs[i]\n",
      "        \n",
      "    print '------------------------------'\n",
      "    \n",
      "    for i in range(Y.size):\n",
      "        if Y[i] == predict[i]:\n",
      "            print Y[i], predict[i], probs[i][0] - probs[i][1], '     ', probs[i]\n",
      "        \n",
      "    print '------------------------------'\n",
      "    \n",
      "    for i in range(Y.size):\n",
      "        print probs[i][0] + probs[i][1]"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "clf_prob = SGDClassifier(alpha=grid.best_params_['alpha'], \n",
      "                         #learning_rate=grid.best_params_['learning_rate'],\n",
      "                         loss=grid.best_params_['loss'], \n",
      "                         eta0=grid.best_params_['n_iter'],\n",
      "                         #eta0=grid.best_params_['eta0'],\n",
      "                         class_weight='auto')\n",
      "clf_prob.fit(X_train, Y_train)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "foo(clf_prob, X_predict_vshort, Y_predict_vshort)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "clf_prob.predict_log_proba(X_predict_vshort)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "from sklearn.svm import LinearSVC"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "#LinearSVC?"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "from sklearn.svm import SVC"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "SVC?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}