{
 "metadata": {
  "name": "",
  "signature": "sha256:4c12298485e287018cff5182f795178468ee44c85803fec94c3a44fb8644085c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "from pprint import pprint\n",
      "from collections import defaultdict\n",
      "\n",
      "import numpy as np\n",
      "import math\n",
      "import matplotlib.pyplot as plt\n",
      "import random\n",
      "import warnings\n",
      "import copy\n",
      "\n",
      "#import sklearn.tree\n",
      "#import sklearn.ensemble\n",
      "#import sklearn.decomposition\n",
      "#from sklearn.naive_bayes import GaussianNB\n",
      "#from sklearn.linear_model import LogisticRegression\n",
      "#import sklearn.linear_model\n",
      "#from sklearn.svm import SVC\n",
      "\n",
      "from sklearn.neural_network import BernoulliRBM\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import metrics\n",
      "\n",
      "import sys\n",
      "sys.path.append('./dev')\n",
      "\n",
      "from ml_plot import plot_validation_curve\n",
      "from ml_plot import my_plot_learning_curve\n",
      "from ml_plot import plot_prediction_curve\n",
      "from ml_plot import get_dataset, eval_predictions\n",
      "from ml_plot import PredictCV, PredictCV_TrainTest\n",
      "from ml_plot import PredictCV_TrainTestValidate\n",
      "\n",
      "sys.path.append('/Users/doug/iPython/multilayer_perceptron')\n",
      "from multilayer_perceptron  import MultilayerPerceptronClassifier\n",
      "from multilayer_perceptron_ddw  import MultilayerPerceptronClassifier as MultilayerPerceptronClassifier2\n",
      "from sklearn.neural_network import BernoulliRBM"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# PROJECT = 'nova'\n",
      "# PROJECT = 'swift'\n",
      "# PROJECT = 'cinder'\n",
      "PROJECT = 'heat'\n",
      "# PROJECT = 'glance'\n",
      "\n",
      "# IMPORTANCE = 'crit'\n",
      "# IMPORTANCE = 'high+'\n",
      "IMPORTANCE = 'med+'\n",
      "# IMPORTANCE = 'low+'\n",
      "\n",
      "# SIZE = 100\n",
      "#SIZE = 250\n",
      "# SIZE = 0.1\n",
      "SIZE = 0.5\n",
      "\n",
      "SCORING = 'f1'         # (precision * recall) / (precision + recall)\n",
      "# SCORING = 'accuracy'   # (TP + TN) / all values\n",
      "# SCORING = 'precision'  # TP / (TP + FP)\n",
      "# SCORING = 'recall'     # TP / (TP + FN)\n",
      "# SCORING = 'average_precision'\n",
      "# SCORING = 'roc_auc'\n",
      "\n",
      "JOBS = 4\n",
      "VERBOSE = True\n",
      "\n",
      "warnings.filterwarnings('ignore', 'F-score is ill-defined')\n",
      "warnings.filterwarnings('ignore', 'overflow encountered in exp')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HIDDEN_LAYER_1 = 200\n",
      "HIDDEN_LAYER_2 = 20"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def tune_rbm(rbm, X, runaway=2000, min_lr=0.000001, verbose=False):\n",
      "    rbm.fit(X)\n",
      "    error = abs(np.mean(rbm.score_samples(X)))\n",
      "    if verbose:\n",
      "        print 'Initial Error:', error\n",
      "    count = 0\n",
      "    best_params = None\n",
      "    best_error = None\n",
      "    while runaway > 0:\n",
      "        runaway -= 1\n",
      "        rbm.partial_fit(X)\n",
      "        new_error = abs(np.mean(rbm.score_samples(X)))\n",
      "        #print new_error\n",
      "        if verbose:\n",
      "            print '.',\n",
      "    \n",
      "        if new_error > error:\n",
      "            count += 1\n",
      "            if count > 1:\n",
      "                params = rbm.get_params('learning_rate')\n",
      "                learning_rate = params['learning_rate']\n",
      "                learning_rate = learning_rate * 0.7\n",
      "                if learning_rate < min_lr:\n",
      "                    break\n",
      "                if verbose:\n",
      "                    print 'learning rate set to:', learning_rate, 'Current best error:', best_error\n",
      "                rbm.set_params(learning_rate=learning_rate)\n",
      "                # Backup learner\n",
      "                if best_params:\n",
      "                    rbm.intercept_hidden_ = best_params['intercept_hidden_']                    \n",
      "                    rbm.intercept_visible_ = best_params['intercept_visible_']\n",
      "                    rbm.components_ = best_params['components_']\n",
      "                    new_error = best_error\n",
      "                count = 0\n",
      "        else:\n",
      "            count = 0\n",
      "            if not best_error or new_error < best_error:\n",
      "                best_error = new_error\n",
      "                best_params = {'intercept_hidden_': rbm.intercept_hidden_,\n",
      "                               'intercept_visible_': rbm.intercept_visible_,\n",
      "                               'components_': rbm.components_}\n",
      "        error = new_error\n",
      "    print 'Final_error:', best_error\n",
      "    rbm.intercept_hidden_ = best_params['intercept_hidden_']                    \n",
      "    rbm.intercept_visible_ = best_params['intercept_visible_']\n",
      "    rbm.components_ = best_params['components_']\n",
      "    return best_error, rbm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def best_of_the_best_rbm(X, n_components, count=10, start_lr=0.1, min_lr=0.01, verbose=False):\n",
      "    results = []\n",
      "    for i in range(count):\n",
      "        rbm = BernoulliRBM(n_components=n_components,\n",
      "                   learning_rate=start_lr, \n",
      "                   batch_size=len(X), \n",
      "                   n_iter=1, \n",
      "                   verbose=0, \n",
      "                   random_state=None)\n",
      "        best_error, best_rbm = tune_rbm(rbm, X, runaway=2000, min_lr=min_lr, verbose=verbose)\n",
      "        validate_error = abs(np.mean([np.mean(best_rbm.score_samples(X)) for ii in range(30)]))\n",
      "        results.append([validate_error, best_error, best_rbm])\n",
      "        \n",
      "    results = sorted(results, key=lambda x:x[0])\n",
      "    if verbose:\n",
      "        print [validate_error for validate_error, best_error, best_rbm in results]\n",
      "        print [best_error for validate_error, best_error, best_rbm in results]\n",
      "    return results[0]   # best_rbm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mlp_best_of_the_best(X, Y, mlp_params={}, count=10, start_lr=0.1, min_lr=0.01, \n",
      "                         tol1=0.01, runaway1=10, tol2=0.001, runaway2=100,\n",
      "                         skip_rbm=False, verbose=False):\n",
      "    \n",
      "    if 'algorithm' in mlp_params and mlp_params['algorithm'] == 'sgd':\n",
      "        is_sgd = True\n",
      "    else:\n",
      "        is_sgd = False\n",
      "    hidden_l1 = mlp_params['hidden_layer_sizes'][0]\n",
      "    hidden_l2 = mlp_params['hidden_layer_sizes'][1]\n",
      "    \n",
      "    results = []\n",
      "    for i in range(count):\n",
      "        print 'Iteration:', i\n",
      "        # Train first hidden layer\n",
      "        if not skip_rbm:\n",
      "            best_error, best_rbm_1 = tune_rbm(BernoulliRBM(n_components=hidden_l1,\n",
      "                                                       learning_rate=start_lr, \n",
      "                                                       batch_size=len(X), \n",
      "                                                       n_iter=1, \n",
      "                                                       verbose=0, \n",
      "                                                       random_state=None),\n",
      "                                           X,\n",
      "                                           runaway=2000,\n",
      "                                           min_lr=min_lr,\n",
      "                                           verbose=verbose)\n",
      "            train_L1_inputs = best_rbm_1.transform(X)\n",
      "            # Train second hidden layer, using outputs of RBM as inputs to second hidden layer\n",
      "            best_error, best_rbm_2 = tune_rbm(BernoulliRBM(n_components=hidden_l2,\n",
      "                                                       learning_rate=start_lr, \n",
      "                                                       batch_size=len(X), \n",
      "                                                       n_iter=1, \n",
      "                                                       verbose=0, \n",
      "                                                       random_state=None),\n",
      "                                           train_L1_inputs,\n",
      "                                           runaway=2000,\n",
      "                                           min_lr=min_lr,\n",
      "                                           verbose=verbose)\n",
      "        # Create MLP estimater and initialize\n",
      "        mlp_estimator = MultilayerPerceptronClassifier(**mlp_params)\n",
      "        mlp_estimator.set_params(max_iter=1)\n",
      "        mlp_estimator.fit(trainX, trainY)\n",
      "        print 'Unoptimized cost:', mlp_estimator.cost_\n",
      "\n",
      "        \n",
      "        if not skip_rbm:\n",
      "            # now inject initialization values from RBMs\n",
      "            mlp_estimator.layers_coef_[0] = best_rbm_1.components_\n",
      "            mlp_estimator.layers_coef_[1] = best_rbm_2.components_\n",
      "            mlp_estimator.layers_intercept_[0] = best_rbm_1.intercept_hidden_\n",
      "            mlp_estimator.layers_intercept_[1] = best_rbm_2.intercept_hidden_\n",
      "        mlp_estimator.set_params(max_iter=10)\n",
      "        mlp_estimator.set_params(warm_start=True)\n",
      "        \n",
      "        # validate_error = abs(np.mean([np.mean(best_rbm.score_samples(X)) for ii in range(30)]))\n",
      "        # results.append([validate_error, best_error, best_rbm])\n",
      "        \n",
      "        # Continue to optimize until acceptable tolerance achieved\n",
      "        old_cost = mlp_estimator.cost_\n",
      "        runaway = runaway1\n",
      "        first = True\n",
      "        while runaway > 0:\n",
      "            revert = False\n",
      "            print '.',  \n",
      "            checkpoint_learning = mlp_estimator.learning_rate_  \n",
      "            checkpoint_coef = copy.deepcopy(mlp_estimator.layers_coef_) \n",
      "            checkpoint_intercept = copy.deepcopy(mlp_estimator.layers_intercept_)\n",
      "            mlp_estimator.fit(trainX, trainY)\n",
      "            new_cost = mlp_estimator.cost_\n",
      "            print mlp_estimator.cost_, old_cost\n",
      "            if not first and is_sgd and new_cost > old_cost:\n",
      "                new_cost = old_cost\n",
      "                print 'Learning rate was:', checkpoint_learning, \n",
      "                mlp_estimator.learning_rate_ = checkpoint_learning * 0.7\n",
      "                print 'now:', mlp_estimator.learning_rate_\n",
      "                mlp_estimator.layers_coef_ = checkpoint_coef\n",
      "                mlp_estimator.layers_intercept_ = checkpoint_intercept\n",
      "                revert = True\n",
      "            \n",
      "            runaway -= 1\n",
      "            first = False\n",
      "            if not revert and abs(old_cost - new_cost)/ old_cost < tol1:\n",
      "                print 'tol1 achieved'\n",
      "                break\n",
      "            old_cost = new_cost\n",
      "        print 'cost:', mlp_estimator.cost_\n",
      "        results.append([mlp_estimator.cost_, mlp_estimator])\n",
      "\n",
      "    # select best estimator    \n",
      "    results = sorted(results, key=lambda x:x[0])\n",
      "    mlp_estimator = results[0][1]\n",
      "    if verbose:\n",
      "        print [cost for cost, best_mlp in results]\n",
      "    mlp_estimator = results[0][1]\n",
      "        \n",
      "    # now further optimize best mlp\n",
      "    print 'now further optimizing result'\n",
      "    old_cost = mlp_estimator.cost_\n",
      "    mlp_estimator.set_params(max_iter=10)\n",
      "    runaway = runaway2\n",
      "    first = True\n",
      "    while runaway > 0:\n",
      "            revert = False\n",
      "            print '.', \n",
      "            checkpoint_learning = mlp_estimator.learning_rate_\n",
      "            checkpoint_coef = copy.deepcopy(mlp_estimator.layers_coef_) \n",
      "            checkpoint_intercept = copy.deepcopy(mlp_estimator.layers_intercept_)\n",
      "            mlp_estimator.fit(trainX, trainY)\n",
      "            new_cost = mlp_estimator.cost_\n",
      "            print mlp_estimator.cost_, old_cost\n",
      "            if not first and is_sgd and new_cost > old_cost:\n",
      "                new_cost = old_cost\n",
      "                print 'Learning rate was:', checkpoint_learning, \n",
      "                mlp_estimator.learning_rate_ = checkpoint_learning * 0.7\n",
      "                print 'now:', mlp_estimator.learning_rate_\n",
      "                mlp_estimator.layers_coef_ = checkpoint_coef\n",
      "                mlp_estimator.layers_intercept_ = checkpoint_intercept\n",
      "                revert = True\n",
      "            \n",
      "            runaway -= 1\n",
      "            first = False\n",
      "            if not revert and abs(old_cost - new_cost)/ old_cost < tol2:\n",
      "                print 'tol2 achieved'\n",
      "                break\n",
      "                \n",
      "            old_cost = new_cost\n",
      "    print 'cost:', mlp_estimator.cost_\n",
      "    \n",
      "    return mlp_estimator.cost_, mlp_estimator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%capture\n",
      "Y, X = get_dataset(PROJECT, IMPORTANCE)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for trainX, trainY, testX, testY in PredictCV_TrainTest(X, Y, history=500, future=500, n_iter=1):\n",
      "    pass\n",
      "print trainX.shape\n",
      "print trainY.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(500, 2374)\n",
        "(500,)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Start of Analysis"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Compute initialization parameters using RBM"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rbm = BernoulliRBM(n_components=HIDDEN_LAYER_1,\n",
      "                   learning_rate=0.1, \n",
      "                   batch_size=500, \n",
      "                   n_iter=1, \n",
      "                   verbose=0, \n",
      "                   random_state=None)\n",
      "best_error, best_rbm = tune_rbm(rbm, trainX, runaway=2000, min_lr=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Final_error: 12.0294067988\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print abs(np.mean([np.mean(rbm.score_samples(trainX)) for x in range(30)]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "53.5016444936\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mlp_select_best(X, Y, testX, testY, mlp_params={}, count=10, start_lr=0.1, min_lr=0.01, \n",
      "                    tol=0.001, runaway=10, verbose=False):\n",
      "    \n",
      "    if 'algorithm' in mlp_params and mlp_params['algorithm'] == 'sgd':\n",
      "        is_sgd = True\n",
      "    else:\n",
      "        is_sgd = False\n",
      "    hidden_l1 = mlp_params['hidden_layer_sizes'][0]\n",
      "    hidden_l2 = mlp_params['hidden_layer_sizes'][1]\n",
      "    \n",
      "    results = []\n",
      "    for i in range(count):\n",
      "        print 'Iteration:', i\n",
      "\n",
      "        # Create MLP estimater and initialize\n",
      "        mlp_estimator = MultilayerPerceptronClassifier(**mlp_params)\n",
      "        mlp_estimator.set_params(max_iter=1)\n",
      "        mlp_estimator.fit(trainX, trainY)\n",
      "        #print 'Unoptimized cost:', mlp_estimator.cost_\n",
      "\n",
      "        mlp_estimator.set_params(max_iter=10)\n",
      "        mlp_estimator.set_params(warm_start=True)\n",
      "        \n",
      "        # validate_error = abs(np.mean([np.mean(best_rbm.score_samples(X)) for ii in range(30)]))\n",
      "        # results.append([validate_error, best_error, best_rbm])\n",
      "        \n",
      "        # Continue to optimize until acceptable tolerance achieved\n",
      "        old_cost = mlp_estimator.cost_\n",
      "        runaway_ = runaway\n",
      "        first = True\n",
      "        while runaway_ > 0:\n",
      "            print '.',  \n",
      "            checkpoint_learning = mlp_estimator.learning_rate_  \n",
      "            checkpoint_coef = copy.deepcopy(mlp_estimator.layers_coef_) \n",
      "            checkpoint_intercept = copy.deepcopy(mlp_estimator.layers_intercept_)\n",
      "            mlp_estimator.fit(trainX, trainY)\n",
      "            new_cost = mlp_estimator.cost_\n",
      "            #print mlp_estimator.cost_, old_cost\n",
      "            \n",
      "            runaway_ -= 1\n",
      "            if abs(old_cost - new_cost)/ old_cost < tol:\n",
      "                print 'tol achieved'\n",
      "                break\n",
      "            old_cost = new_cost\n",
      "        print 'cost:', mlp_estimator.cost_\n",
      "        f1_train = metrics.f1_score(trainY, mlp_estimator.predict(trainX))\n",
      "        f1_test = metrics.f1_score(testY, mlp_estimator.predict(testX))\n",
      "        print 'F1:', f1_test, f1_train\n",
      "        results.append([f1_test, mlp_estimator])\n",
      "        \n",
      "    # select best estimator \n",
      "\n",
      "    results = sorted(results, key=lambda x:x[0], reverse=True)\n",
      "\n",
      "    best_f1_test, best_mlp = results[0]\n",
      "    predict_testY = best_mlp.predict(testX)\n",
      "    print\n",
      "    print 'Best result'\n",
      "    print 'Cost:', best_mlp.cost_\n",
      "    print metrics.classification_report(testY, predict_testY)\n",
      "    print 'Confusion Matrix:'\n",
      "    print metrics.confusion_matrix(trainY, predict_testY)\n",
      "    \n",
      "    return best_f1_test, mlp_estimator"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 178
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mlp_params = dict(alpha=0.001, hidden_layer_sizes=(HIDDEN_LAYER_1, HIDDEN_LAYER_2),\n",
      "                  #algorithm='sgd',\n",
      "                  learning_rate='constant', learning_rate_init=2,\n",
      "                  power_t=0.3, max_iter=1, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "best_f1_test, best_mlp = mlp_select_best(trainX, trainY, testX, testY,mlp_params, count=2, \n",
      "                                          runaway=30, tol=0.005, verbose=True)\n",
      "print 'Best F1 Test:', best_f1_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration: 0\n",
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tol1 achieved\n",
        "cost: 0.268384029766\n",
        "F1: 0.341666666667 0.956810631229\n",
        "Iteration: 1\n",
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tol1 achieved\n",
        "cost: 0.24578790935\n",
        "F1: 0.304526748971 0.963455149502\n",
        "\n",
        "Best result\n",
        "Cost: 0.268384029766\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.80      0.78      0.79       385\n",
        "       True       0.33      0.36      0.34       115\n",
        "\n",
        "avg / total       0.69      0.68      0.69       500\n",
        "\n",
        "Confusion Matrix:\n",
        "[[262  86]\n",
        " [113  39]]\n",
        "best cost: 0.341666666667\n"
       ]
      }
     ],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def search_mlp(trainX, trainY, testX, testY, layer_vals, alpha_vals, count=10, runaway=30, tol=0.005):\n",
      "    results = []\n",
      "    for layers in layer_vals:\n",
      "        print 'Testing for layers:', layers\n",
      "        for alpha in alpha_vals:\n",
      "            print\n",
      "            print 'Testing for Alpha:', alpha\n",
      "            print\n",
      "            mlp_params = dict(alpha=alpha, hidden_layer_sizes=layers,\n",
      "                  #algorithm='sgd',\n",
      "                  learning_rate='constant', learning_rate_init=2,\n",
      "                  power_t=0.3, max_iter=1, verbose=False)\n",
      "            best_f1_test, best_mlp = mlp_select_best(trainX, trainY, testX, testY,mlp_params, count=count, \n",
      "                                          runaway=runaway, tol=tol, verbose=True)\n",
      "            results.append([alpha, best_f1_test, best_mlp, layers])\n",
      "    print len(results)\n",
      "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
      "    print 'Best Alpha:', results[0][0]\n",
      "    print 'Best Layers:', results[0][3]\n",
      "    print 'Best F1:', results[0][1]\n",
      "    print 'Best Estimator:', results[0][2]\n",
      "    return results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layer_vals = [(400, 50), (400, 100), (400, 200), (400, 400),\n",
      "               (800, 100), (800, 200), (800, 400), (800, 800),\n",
      "               (200, 20), (200, 40), (200, 100), (200, 200)]\n",
      "alpha_vals = [#10, 1.0, 0.1, \n",
      "              0.033, 0.01, 0.0033, 0.001, 0.00033, 0.0001, 0.000033, 0.00001]\n",
      "    \n",
      "results2 = search_mlp(trainX, trainY, testX, testY, layer_vals, alpha_vals, count=10, runaway=100, tol=0.005)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "layer_vals = [(1000, 100, 10)]\n",
      "alpha_vals = [0.0033]\n",
      "    \n",
      "results2 = search_mlp(trainX, trainY, testX, testY, layer_vals, alpha_vals, count=5, runaway=100, tol=0.005)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Testing for layers: (1000, 100, 10)\n",
        "\n",
        "Testing for Alpha: 0.0033\n",
        "\n",
        "Iteration: 0\n",
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tol achieved\n",
        "cost: 0.694091115286\n",
        "F1:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0 0.0\n",
        "Iteration: 1\n",
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tol achieved\n",
        "cost: 1.57934739345\n",
        "F1:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.307692307692 0.501930501931\n",
        "Iteration: 2\n",
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tol achieved\n",
        "cost: 0.613971129144\n",
        "F1:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.0 0.0\n",
        "Iteration: 3\n",
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tol achieved\n",
        "cost: 0.219327192605\n",
        "F1:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.330508474576 0.960264900662\n",
        "Iteration: 4\n",
        "."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " . "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "tol achieved\n",
        "cost: 0.755800349711\n",
        "F1:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.384 0.842809364548\n",
        "\n",
        "Best result\n",
        "Cost: 0.755800349711\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.82      0.77      0.79       385\n",
        "       True       0.36      0.42      0.38       115\n",
        "\n",
        "avg / total       0.71      0.69      0.70       500\n",
        "\n",
        "Confusion Matrix:\n",
        "[[257  91]\n",
        " [108  44]]\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Best Alpha: 0.0033\n",
        "Best Layers: (1000, 100, 10)\n",
        "Best F1: 0.384\n",
        "Best Estimator: MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                alpha=0.0033, batch_size=200,\n",
        "                hidden_layer_sizes=(1000, 100, 10),\n",
        "                learning_rate='constant', learning_rate_init=2,\n",
        "                max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                tol=1e-05, verbose=False, warm_start=True)\n"
       ]
      }
     ],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 183,
       "text": [
        "[[0.033,\n",
        "  0.39306358381502893,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(800, 800),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 800)],\n",
        " [0.0033,\n",
        "  0.3776223776223776,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(400, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (400, 200)],\n",
        " [0.001,\n",
        "  0.37751004016064255,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.0033,\n",
        "  0.37735849056603776,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 400), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 400)],\n",
        " [0.001,\n",
        "  0.37704918032786888,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(800, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 100)],\n",
        " [0.001,\n",
        "  0.37499999999999994,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(800, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 200)],\n",
        " [0.0033,\n",
        "  0.37450199203187262,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 100)],\n",
        " [0.033,\n",
        "  0.37398373983739841,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(800, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 200)],\n",
        " [0.0033,\n",
        "  0.37398373983739841,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.00033,\n",
        "  0.37398373983739835,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 800), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 800)],\n",
        " [0.0033,\n",
        "  0.37229437229437229,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 800), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 800)],\n",
        " [0.0001,\n",
        "  0.3713080168776372,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.00033,\n",
        "  0.37037037037037041,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 200)],\n",
        " [0.001,\n",
        "  0.36974789915966388,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(400, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 400)],\n",
        " [0.01,\n",
        "  0.36939313984168864,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(400, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 400)],\n",
        " [0.001,\n",
        "  0.36842105263157898,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(800, 800),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 800)],\n",
        " [0.01,\n",
        "  0.3682008368200837,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(800, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 200)],\n",
        " [0.0033,\n",
        "  0.36752136752136755,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(400, 400), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (400, 400)],\n",
        " [0.033,\n",
        "  0.3671875,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(800, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 400)],\n",
        " [0.0033,\n",
        "  0.36585365853658541,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(400, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (400, 100)],\n",
        " [0.0001,\n",
        "  0.36585365853658541,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(400, 400), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (400, 400)],\n",
        " [0.01,\n",
        "  0.36514522821576761,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.00033,\n",
        "  0.36437246963562753,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(400, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (400, 200)],\n",
        " [0.0033,\n",
        "  0.36363636363636365,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.0033,\n",
        "  0.36363636363636359,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 200)],\n",
        " [0.01,\n",
        "  0.36206896551724138,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(800, 800),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 800)],\n",
        " [0.01,\n",
        "  0.36134453781512604,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(800, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 100)],\n",
        " [0.0033,\n",
        "  0.36065573770491804,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.001,\n",
        "  0.36051502145922742,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(800, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 400)],\n",
        " [0.01,\n",
        "  0.36036036036036029,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(400, 50),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 50)],\n",
        " [0.00033,\n",
        "  0.36015325670498088,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 100)],\n",
        " [0.01,\n",
        "  0.35983263598326365,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.0001,\n",
        "  0.3596491228070175,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 800), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 800)],\n",
        " [0.0001,\n",
        "  0.35918367346938779,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.001,\n",
        "  0.35833333333333334,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(400, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 200)],\n",
        " [0.01,\n",
        "  0.35833333333333334,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.001,\n",
        "  0.35772357723577231,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.00033,\n",
        "  0.35772357723577231,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.0033,\n",
        "  0.35744680851063826,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.0001,\n",
        "  0.35684647302904565,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 200)],\n",
        " [0.0033,\n",
        "  0.3559322033898305,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200, hidden_layer_sizes=(400, 50),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 50)],\n",
        " [0.01,\n",
        "  0.3559322033898305,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(800, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 400)],\n",
        " [0.0001,\n",
        "  0.3559322033898305,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 400), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 400)],\n",
        " [0.00033,\n",
        "  0.35390946502057608,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(400, 400), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (400, 400)],\n",
        " [0.0001,\n",
        "  0.35344827586206895,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.001,\n",
        "  0.35341365461847385,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.00033,\n",
        "  0.35294117647058826,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(400, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (400, 100)],\n",
        " [0.00033,\n",
        "  0.35294117647058826,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.0001,\n",
        "  0.35245901639344263,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200, hidden_layer_sizes=(400, 50),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 50)],\n",
        " [0.01,\n",
        "  0.35193133047210301,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.001,\n",
        "  0.35193133047210301,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.0001,\n",
        "  0.35146443514644349,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 100)],\n",
        " [0.0001,\n",
        "  0.3510204081632653,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(400, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (400, 200)],\n",
        " [0.00033,\n",
        "  0.35000000000000009,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(400, 50), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (400, 50)],\n",
        " [0.01,\n",
        "  0.35000000000000009,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(400, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 200)],\n",
        " [0.01,\n",
        "  0.34893617021276596,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(400, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 100)],\n",
        " [0.001,\n",
        "  0.34854771784232363,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(400, 50),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 50)],\n",
        " [0.00033,\n",
        "  0.34677419354838707,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 40), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.00033,\n",
        "  0.34632034632034631,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(800, 400), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (800, 400)],\n",
        " [0.0001,\n",
        "  0.34567901234567899,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(400, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (400, 100)],\n",
        " [0.001,\n",
        "  0.34453781512605042,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(400, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 100)],\n",
        " [0.00033,\n",
        "  0.34400000000000003,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 20), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.0001,\n",
        "  0.34166666666666662,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.033,\n",
        "  0.31746031746031744,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(400, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 400)],\n",
        " [0.033,\n",
        "  0.3125,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(400, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 100)],\n",
        " [0.033,\n",
        "  0.31016042780748665,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(400, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 200)],\n",
        " [0.033,\n",
        "  0.287292817679558,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.033,\n",
        "  0.2696629213483146,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(400, 50),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 50)],\n",
        " [0.033,\n",
        "  0.25000000000000006,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(800, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 100)],\n",
        " [0.033,\n",
        "  0.23749999999999999,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.033,\n",
        "  0.20645161290322581,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(400, 50),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 50)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(400, 50),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 50)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(400, 50),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 50)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(400, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 100)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(400, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 100)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(400, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 100)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(400, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 200)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(400, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 200)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(400, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 200)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(400, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 400)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(400, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 400)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(400, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (400, 400)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(800, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 100)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(800, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 100)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(800, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 100)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(800, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 200)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(800, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 200)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(800, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 200)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(800, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 400)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(800, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 400)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(800, 400),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 400)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(800, 800),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 800)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(800, 800),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 800)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(800, 800),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (800, 800)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.033,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)]]"
       ]
      }
     ],
     "prompt_number": 183
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Earlier Results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 181,
       "text": [
        "[[0.0001,\n",
        "  0.41269841269841268,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.033,\n",
        "  0.37398373983739841,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.0033,\n",
        "  0.36514522821576761,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.0033,\n",
        "  0.36286919831223624,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.001,\n",
        "  0.36220472440944879,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.0033,\n",
        "  0.36213991769547327,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.00033,\n",
        "  0.36213991769547327,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 20), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.00033,\n",
        "  0.36213991769547327,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.001,\n",
        "  0.35983263598326365,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.0001,\n",
        "  0.35918367346938779,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 200), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.01,\n",
        "  0.35897435897435903,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.01,\n",
        "  0.3559322033898305,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.0033,\n",
        "  0.35443037974683539,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.001,\n",
        "  0.35294117647058826,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.0001,\n",
        "  0.35245901639344263,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.001,\n",
        "  0.34854771784232363,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.001, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.00033,\n",
        "  0.34854771784232363,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.01,\n",
        "  0.34745762711864409,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.01,\n",
        "  0.34745762711864409,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.01, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.00033,\n",
        "  0.34024896265560167,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.00033, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 40), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.0001,\n",
        "  0.34024896265560167,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.0001, batch_size=200,\n",
        "                  hidden_layer_sizes=(200, 100), learning_rate='constant',\n",
        "                  learning_rate_init=2, max_iter=10, power_t=0.3,\n",
        "                  random_state=None, shuffle=False, tol=1e-05, verbose=False,\n",
        "                  warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.033,\n",
        "  0.2824858757062147,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.033,\n",
        "  0.27932960893854752,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.033,\n",
        "  0.1702127659574468,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.033, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(200, 20),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 20)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(200, 40),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 40)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(200, 100),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 100)],\n",
        " [10,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=10, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)],\n",
        " [1.0,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=1.0, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)],\n",
        " [0.1,\n",
        "  0.0,\n",
        "  MultilayerPerceptronClassifier(activation='relu', algorithm='l-bfgs',\n",
        "                  alpha=0.1, batch_size=200, hidden_layer_sizes=(200, 200),\n",
        "                  learning_rate='constant', learning_rate_init=2,\n",
        "                  max_iter=10, power_t=0.3, random_state=None, shuffle=False,\n",
        "                  tol=1e-05, verbose=False, warm_start=True),\n",
        "  (200, 200)]]"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Training set results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.classification_report(trainY, best_mlp.predict(trainX))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.98      0.98      0.98       348\n",
        "       True       0.96      0.95      0.96       152\n",
        "\n",
        "avg / total       0.97      0.97      0.97       500\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'F1:', metrics.f1_score(trainY, best_mlp.predict(trainX))\n",
      "print\n",
      "print 'Confusion Matrix:'\n",
      "print metrics.confusion_matrix(trainY, best_mlp.predict(trainX))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F1: 0.957095709571\n",
        "\n",
        "Confusion Matrix:\n",
        "[[342   6]\n",
        " [  7 145]]\n"
       ]
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test set results"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print metrics.classification_report(testY, best_mlp.predict(testX))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "      False       0.80      0.77      0.79       385\n",
        "       True       0.31      0.35      0.33       115\n",
        "\n",
        "avg / total       0.69      0.68      0.68       500\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 130
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'F1:', metrics.f1_score(testY, best_mlp.predict(testX))\n",
      "print\n",
      "print 'Confusion Matrix:'\n",
      "print metrics.confusion_matrix(testY, best_mlp.predict(testX))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "F1: 0.330578512397\n",
        "\n",
        "Confusion Matrix:\n",
        "[[298  87]\n",
        " [ 75  40]]\n"
       ]
      }
     ],
     "prompt_number": 131
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Boneyard"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Type:            ABCMeta\n",
      "String form:     <class 'multilayer_perceptron.MultilayerPerceptronClassifier'>\n",
      "File:            /Users/doug/iPython/multilayer_perceptron/multilayer_perceptron.py\n",
      "Init definition: MultilayerPerceptronClassifier(self, hidden_layer_sizes=(100,), activation='relu', algorithm='l-bfgs', alpha=1e-05, batch_size=200, learning_rate='constant', learning_rate_init=0.5, power_t=0.5, max_iter=200, shuffle=False, random_state=None, tol=1e-05, verbose=False, warm_start=False)\n",
      "Docstring:\n",
      "Multi-layer Perceptron classifier.\n",
      "\n",
      "This algorithm optimizes the logistic loss function using l-bfgs or\n",
      "gradient descent.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "hidden_layer_sizes : tuple, length = n_layers - 2, default (100,)\n",
      "    The ith index in list contains the number of neurons in the ith\n",
      "    hidden layer.\n",
      "\n",
      "activation : {'logistic', 'tanh', 'relu'}, default 'relu'\n",
      "    Activation function for the hidden layer.\n",
      "\n",
      "    -  'logistic', the logistic sigmoid function,\n",
      "        returns f(x) = 1 / (1 + exp(x)).\n",
      "\n",
      "    - 'tanh', the hyperbolic tan function,\n",
      "       returns f(x) = tanh(x).\n",
      "\n",
      "    - 'relu', the rectified linear unit function,\n",
      "       returns f(x) = max(0, x)\n",
      "\n",
      "algorithm : {'l-bfgs', 'sgd'}, default 'l-bfgs'\n",
      "    The algorithm for weight optimization.  Defaults to 'l-bfgs'\n",
      "\n",
      "    - 'l-bfgs' is an optimization algorithm in the family of\n",
      "      quasi-Newton methods.\n",
      "\n",
      "    - 'sgd' refers to stochastic gradient descent.\n",
      "\n",
      "alpha : float, optional, default 0.00001\n",
      "    L2 penalty (regularization term) parameter.\n",
      "\n",
      "batch_size : int, optional, default 200\n",
      "    Size of minibatches in SGD optimizer.\n",
      "    If you select the algorithm as 'l-bfgs',\n",
      "    then the classifier will not use minibatches.\n",
      "\n",
      "learning_rate : {'constant', 'invscaling'}, default 'constant'\n",
      "    Base learning rate for weight updates.\n",
      "\n",
      "    -'constant', as it stands,  keeps the learning rate\n",
      "     'learning_rate_init' constant throughout training.\n",
      "     learning_rate_ = learning_rate_init\n",
      "\n",
      "    -'invscaling' gradually decreases the learning rate 'learning_rate_' at\n",
      "      each time step 't' using an inverse scaling exponent of 'power_t'.\n",
      "      learning_rate_ = learning_rate_init / pow(t, power_t)\n",
      "\n",
      "max_iter : int, optional, default 200\n",
      "    Maximum number of iterations. The algorithm\n",
      "    iterates until convergence (determined by 'tol') or\n",
      "    this number of iterations.\n",
      "\n",
      "random_state : int or RandomState, optional, default None\n",
      "    State of or seed for random number generator.\n",
      "\n",
      "shuffle : bool, optional, default False\n",
      "    Whether to shuffle samples in each iteration before extracting\n",
      "    minibatches.\n",
      "\n",
      "tol : float, optional, default 1e-5\n",
      "    Tolerance for the optimization. When the loss at iteration i+1 differs\n",
      "    less than this amount from that at iteration i, convergence is\n",
      "    considered to be reached and the algorithm exits.\n",
      "\n",
      "learning_rate_init : double, optional, default 0.5\n",
      "    The initial learning rate used. It controls the step-size\n",
      "    in updating the weights.\n",
      "\n",
      "power_t : double, optional, default 0.5\n",
      "    The exponent for inverse scaling learning rate.\n",
      "    It is used in updating learning_rate_init when the learning_rate\n",
      "    is set to 'invscaling'.\n",
      "\n",
      "verbose : bool, optional, default False\n",
      "    Whether to print progress messages to stdout.\n",
      "\n",
      "warm_start : bool, optional, default False\n",
      "    When set to True, reuse the solution of the previous\n",
      "    call to fit as initialization, otherwise, just erase the\n",
      "    previous solution.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "`classes_` : array or list of array of shape (n_classes,)\n",
      "    Class labels for each output.\n",
      "\n",
      "`cost_` : float\n",
      "    The current cost value computed by the loss function.\n",
      "\n",
      "`label_binarizer_` : LabelBinarizer\n",
      "    A LabelBinarizer object trained on the training set.\n",
      "\n",
      "`layers_coef_` : list, length n_layers - 1\n",
      "    The ith element in the list represents the weight matrix corresponding\n",
      "    to layer i.\n",
      "\n",
      "`layers_intercept_` : list, length n_layers - 1\n",
      "    The ith element in the list represents the bias vector corresponding to\n",
      "    layer i + 1.\n",
      "\n",
      "`learning_rate_` : float\n",
      "    The current learning rate.\n",
      "\n",
      "n_iter_ : int,\n",
      "    The current number of iterations the algorithm has ran.\n",
      "\n",
      "n_layers_ : int\n",
      "    Number of layers.\n",
      "\n",
      "`n_outputs_` : int\n",
      "    Number of outputs.\n",
      "\n",
      "`out_activation_` : string\n",
      "    Name of the output activation function.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "MultilayerPerceptronClassifier trains iteratively since at each time step\n",
      "the partial derivatives of the loss function with respect to the model\n",
      "parameters are computed to update the parameters.\n",
      "\n",
      "It can also use regularizer as a penalty term added to the loss function\n",
      "that shrinks model parameters towards zero.\n",
      "\n",
      "This implementation works with data represented as dense and sparse numpy\n",
      "arrays of floating point values for the features.\n",
      "\n",
      "References\n",
      "----------\n",
      "Hinton, Geoffrey E.\n",
      "    \"Connectionist learning procedures.\" Artificial intelligence 40.1\n",
      "    (1989): 185-234.\n",
      "\n",
      "Glorot, Xavier, and Yoshua Bengio. \"Understanding the difficulty of\n",
      "    training deep feedforward neural networks.\" International Conference\n",
      "    on Artificial Intelligence and Statistics. 2010."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}